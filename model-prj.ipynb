{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6641062,"sourceType":"datasetVersion","datasetId":2093157},{"sourceId":317658,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":268032,"modelId":289061}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install required packages\nprint(\"Installing packages...\")\n!pip install swifter gensim newsapi-python -q\nprint(\"Packages installed.\")\n\n# Import libraries\nimport numpy as np\nimport pandas as pd\nimport os\nimport re\nfrom multiprocessing import Pool, cpu_count\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(f\"Found input file: {os.path.join(dirname, filename)}\")\n\nimport re\nimport nltk\nimport zipfile\nnltk.download('stopwords')\nnltk.download('wordnet', download_dir='/kaggle/working/nltk_data')\nnltk.download('vader_lexicon')\nnltk.data.path.append('/kaggle/working/nltk_data')\nprint(\"Checking NLTK wordnet resource...\")\nwordnet_zip = '/kaggle/working/nltk_data/corpora/wordnet.zip'\nif os.path.exists(wordnet_zip):\n    print(f\"Unzipping wordnet from {wordnet_zip}...\")\n    with zipfile.ZipFile(wordnet_zip, 'r') as zip_ref:\n        zip_ref.extractall('/kaggle/working/nltk_data/corpora')\n    os.remove(wordnet_zip)\n    print(\"Wordnet unzipped and zip file removed.\")\nelse:\n    print(\"Wordnet already unzipped or not downloaded as zip.\")\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nimport swifter\nimport string\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Embedding, SpatialDropout1D, LSTM, Dense, Dropout, Concatenate, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.mixed_precision import set_global_policy\nfrom gensim.models import Word2Vec\nimport pickle\nfrom IPython.display import FileLink\nimport gc\n\n# Enable mixed precision and multi-GPU\nset_global_policy('mixed_float16')\nstrategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\", \"/gpu:1\"])\nprint(f\"GPUs in use: {strategy.num_replicas_in_sync}\")\n\n# Load and clean dataset\nprint(\"Loading WELFake dataset...\")\ndf = pd.read_csv(\"/kaggle/input/fake-news-classification/WELFake_Dataset.csv\")\ndf = df.dropna(subset=['title', 'text', 'label'])\ndf['text'] = df['title'].astype(str) + \" \" + df['text'].astype(str)\nprint(f\"Cleaned dataset shape: {df.shape}\")\n\n# Feature engineering with swifter\nprint(\"Engineering features...\")\nstop_words = set(stopwords.words('english')) - {'not'}\nlemmatizer = WordNetLemmatizer()\nsia = nltk.sentiment.vader.SentimentIntensityAnalyzer()\n\ndef count_words(text): return len(text.split()) if isinstance(text, str) else 0\ndef count_chars(text): return len(text) if isinstance(text, str) else 0\ndef uppercase_ratio(text): return sum(1 for c in text if c.isupper()) / len(text) if isinstance(text, str) and len(text) > 0 else 0\ndef punctuation_count(text): return sum(1 for c in text if c in string.punctuation) if isinstance(text, str) else 0\ndef sentiment_polarity(text): return sia.polarity_scores(text)['compound'] if isinstance(text, str) else 0\n\nfor col in ['title', 'text']:\n    df[f'{col}_word_count'] = df[col].swifter.apply(count_words)\n    df[f'{col}_char_count'] = df[col].swifter.apply(count_chars)\n    df[f'{col}_uppercase_ratio'] = df[col].swifter.apply(uppercase_ratio)\n    df[f'{col}_punctuation_count'] = df[col].swifter.apply(punctuation_count)\n    df[f'{col}_sentiment'] = df[col].swifter.apply(sentiment_polarity)\n\nnumerical_features = ['title_word_count', 'text_word_count', 'title_char_count', 'text_char_count',\n                      'title_uppercase_ratio', 'text_uppercase_ratio', 'title_punctuation_count',\n                      'text_punctuation_count', 'title_sentiment', 'text_sentiment']\nprint(\"Features engineered.\")\n\n# Preprocessing with multiprocessing\ndef preprocess_text(text):\n    if not isinstance(text, str) or not text.strip(): return \"\"\n    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", text.lower())\n    words = text.split()\n    return \" \".join(lemmatizer.lemmatize(word) for word in words if word not in stop_words or word == 'not')\n\nprint(\"Preprocessing texts with multiprocessing...\")\nwith Pool(cpu_count()) as pool:\n    df['preprocessed_text'] = pool.map(preprocess_text, df['text'].tolist())\ntokenized_texts = [text.split() for text in df['preprocessed_text'].tolist()]\nprint(\"Preprocessing completed.\")\n\n# Train-test split\nX_texts = df['preprocessed_text'].tolist()\nX_num = df[numerical_features].values\ny = df['label'].values\nX_train_texts, X_test_texts, X_train_num, X_test_num, y_train, y_test = train_test_split(\n    X_texts, X_num, y, test_size=0.2, random_state=42, stratify=y\n)\nprint(f\"Train size: {len(X_train_texts)}, Test size: {len(X_test_texts)}\")\n\n# Export preprocessed data\nprint(\"Exporting preprocessed data...\")\nos.makedirs('/kaggle/working/output', exist_ok=True)\ntrain_df = pd.DataFrame({'preprocessed_text': X_train_texts, 'label': y_train})\ntrain_df[numerical_features] = X_train_num\ntest_df = pd.DataFrame({'preprocessed_text': X_test_texts, 'label': y_test})\ntest_df[numerical_features] = X_test_num\ntrain_df.to_csv('/kaggle/working/output/train_preprocessed.csv', index=False)\ntest_df.to_csv('/kaggle/working/output/test_preprocessed.csv', index=False)\nprint(\"Datasets saved.\")\ndisplay(FileLink('/kaggle/working/output/train_preprocessed.csv'))\ndisplay(FileLink('/kaggle/working/output/test_preprocessed.csv'))\n\n# Tokenization and padding\nmax_num_words = 20000\nmax_sequence_length = 100\ntokenizer = Tokenizer(num_words=max_num_words, lower=True)\ntokenizer.fit_on_texts(X_train_texts)\nX_train_seq = tokenizer.texts_to_sequences(X_train_texts)\nX_test_seq = tokenizer.texts_to_sequences(X_test_texts)\nX_train_pad = pad_sequences(X_train_seq, maxlen=max_sequence_length)\nX_test_pad = pad_sequences(X_test_seq, maxlen=max_sequence_length)\nword_index = tokenizer.word_index\nprint(f\"Found {len(word_index)} unique tokens.\")\nwith open('/kaggle/working/output/tokenizer.pkl', 'wb') as f:\n    pickle.dump(tokenizer, f)\n    \nprint(\"Tokenizer saved.\")\n\n# Normalize numerical features\nscaler = StandardScaler()\nX_train_num = scaler.fit_transform(X_train_num)\nX_test_num = scaler.transform(X_test_num)\nwith open('/kaggle/working/output/scaler.pkl', 'wb') as f:\n    pickle.dump(scaler, f)\nprint(\"Scaler saved.\")\n\n# Train Word2Vec\nprint(\"Training Word2Vec...\")\nw2v_model = Word2Vec(sentences=tokenized_texts, vector_size=100, window=5, min_count=1, workers=cpu_count(), sg=1, seed=42)\nembedding_dim = 100\nnum_words = min(max_num_words, len(word_index) + 1)\nembedding_matrix = np.zeros((num_words, embedding_dim))\nfor word, i in word_index.items():\n    if i >= max_num_words: continue\n    if word in w2v_model.wv: embedding_matrix[i] = w2v_model.wv[word]\nprint(\"Word2Vec trained.\")\n\n# Build model with multi-GPU\ndef build_model():\n    text_input = Input(shape=(max_sequence_length,), name=\"text_input\")\n    embedding = Embedding(input_dim=num_words, output_dim=embedding_dim, weights=[embedding_matrix],\n                          input_length=max_sequence_length, trainable=False)(text_input)\n    x = SpatialDropout1D(0.2)(embedding)\n    x = LSTM(128, dropout=0.2, recurrent_dropout=0.2)(x)\n    num_input = Input(shape=(X_train_num.shape[1],), name=\"num_input\")\n    num_x = Dense(32, activation=\"relu\")(num_input)\n    num_x = BatchNormalization()(num_x)\n    num_x = Dropout(0.2)(num_x)\n    merged = Concatenate()([x, num_x])\n    output = Dense(1, activation=\"sigmoid\", dtype='float32')(merged)\n    return Model(inputs=[text_input, num_input], outputs=output)\n\nwith strategy.scope():\n    model = build_model()\n    model.compile(optimizer=Adam(learning_rate=1e-3), loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()\n\n# Data pipeline\nbatch_size = 128 * strategy.num_replicas_in_sync\ntrain_dataset = tf.data.Dataset.from_tensor_slices(((X_train_pad, X_train_num), y_train)).shuffle(10000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\ntest_dataset = tf.data.Dataset.from_tensor_slices(((X_test_pad, X_test_num), y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n\n# Train\nprint(\"Training model...\")\nhistory = model.fit(\n    train_dataset, epochs=10,\n    validation_data=test_dataset,\n    callbacks=[EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n               ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6)],\n    verbose=1\n)\nmodel.save('/kaggle/working/output/lstm_model.h5')\nprint(\"Model saved.\")\ndisplay(FileLink('/kaggle/working/output/lstm_model.h5'))\n\n# Evaluate\ny_pred_prob = model.predict(test_dataset)\ny_pred = (y_pred_prob >= 0.5).astype(int).flatten()\nprint(f\"\\nWord2Vec + LSTM Model Accuracy: {model.evaluate(test_dataset, verbose=0)[1]:.4f}\")\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n\n# Clean up\ndel df, X_train_texts, X_test_texts, X_train_num, X_test_num, X_train_pad, X_test_pad, tokenized_texts\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T06:59:57.848346Z","iopub.execute_input":"2025-04-02T06:59:57.848616Z","iopub.status.idle":"2025-04-02T07:23:34.690561Z","shell.execute_reply.started":"2025-04-02T06:59:57.848591Z","shell.execute_reply":"2025-04-02T07:23:34.689556Z"}},"outputs":[{"name":"stdout","text":"Installing packages...\nPackages installed.\nFound input file: /kaggle/input/fake-news-classification/WELFake_Dataset.csv\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     /kaggle/working/nltk_data...\n[nltk_data]   Unzipping corpora/wordnet.zip.\n[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\nChecking NLTK wordnet resource...\nUnzipping wordnet from /kaggle/working/nltk_data/corpora/wordnet.zip...\nWordnet unzipped and zip file removed.\nGPUs in use: 2\nLoading WELFake dataset...\nCleaned dataset shape: (71537, 4)\nEngineering features...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Pandas Apply:   0%|          | 0/71537 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d3c95b182a04de0992178ea2ff4b16b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Pandas Apply:   0%|          | 0/71537 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba29995e6fea4ca8a611f6aea7462874"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Pandas Apply:   0%|          | 0/71537 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00c631696db14b348ed954ec3cdbccd5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Pandas Apply:   0%|          | 0/71537 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b5c10604db5240aa82d49830e0a5de02"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Pandas Apply:   0%|          | 0/71537 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8504452fc20544399fb685b2b9f17f6c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Pandas Apply:   0%|          | 0/71537 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ad3e7c3016344ed80f99e5437fe1fb5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Pandas Apply:   0%|          | 0/71537 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78da01093fe94a2ea307d0ef182ea025"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Pandas Apply:   0%|          | 0/71537 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d04733bb79944417ac2243d1ce745461"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Pandas Apply:   0%|          | 0/71537 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb67858fa7334c96a4fad281974692a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Pandas Apply:   0%|          | 0/71537 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b351401d058451abb97cdf27b75ca1a"}},"metadata":{}},{"name":"stdout","text":"Features engineered.\nPreprocessing texts with multiprocessing...\nPreprocessing completed.\nTrain size: 57229, Test size: 14308\nExporting preprocessed data...\nDatasets saved.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/output/train_preprocessed.csv","text/html":"<a href='/kaggle/working/output/train_preprocessed.csv' target='_blank'>/kaggle/working/output/train_preprocessed.csv</a><br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/output/test_preprocessed.csv","text/html":"<a href='/kaggle/working/output/test_preprocessed.csv' target='_blank'>/kaggle/working/output/test_preprocessed.csv</a><br>"},"metadata":{}},{"name":"stdout","text":"Found 173238 unique tokens.\nTokenizer saved.\nScaler saved.\nTraining Word2Vec...\nWord2Vec trained.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"functional_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ num_input (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ text_input (\u001b[38;5;33mInputLayer\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ cast_2 (\u001b[38;5;33mCast\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ num_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │      \u001b[38;5;34m2,000,000\u001b[0m │ text_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │            \u001b[38;5;34m352\u001b[0m │ cast_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ spatial_dropout1d_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │              \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)        │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │            \u001b[38;5;34m128\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m117,248\u001b[0m │ spatial_dropout1d_1[\u001b[38;5;34m0\u001b[0m… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],          │\n│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ cast_3 (\u001b[38;5;33mCast\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m161\u001b[0m │ cast_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ num_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ text_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ cast_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ num_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,000</span> │ text_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │ cast_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ spatial_dropout1d_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)        │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │ spatial_dropout1d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ concatenate_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],          │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ cast_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">161</span> │ cast_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,117,889\u001b[0m (8.08 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,117,889</span> (8.08 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m117,825\u001b[0m (460.25 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">117,825</span> (460.25 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,000,064\u001b[0m (7.63 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,000,064</span> (7.63 MB)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Training model...\nEpoch 1/10\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 177ms/step - accuracy: 0.7837 - loss: 0.4190 - val_accuracy: 0.9273 - val_loss: 0.1886 - learning_rate: 0.0010\nEpoch 2/10\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 177ms/step - accuracy: 0.9190 - loss: 0.2025 - val_accuracy: 0.9241 - val_loss: 0.1816 - learning_rate: 0.0010\nEpoch 3/10\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 176ms/step - accuracy: 0.9286 - loss: 0.1810 - val_accuracy: 0.9402 - val_loss: 0.1510 - learning_rate: 0.0010\nEpoch 4/10\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 177ms/step - accuracy: 0.9345 - loss: 0.1645 - val_accuracy: 0.9455 - val_loss: 0.1448 - learning_rate: 0.0010\nEpoch 5/10\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 178ms/step - accuracy: 0.9407 - loss: 0.1552 - val_accuracy: 0.9535 - val_loss: 0.1238 - learning_rate: 0.0010\nEpoch 6/10\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 179ms/step - accuracy: 0.9427 - loss: 0.1458 - val_accuracy: 0.9549 - val_loss: 0.1200 - learning_rate: 0.0010\nEpoch 7/10\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 180ms/step - accuracy: 0.9461 - loss: 0.1371 - val_accuracy: 0.9574 - val_loss: 0.1156 - learning_rate: 0.0010\nEpoch 8/10\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 178ms/step - accuracy: 0.9494 - loss: 0.1303 - val_accuracy: 0.9586 - val_loss: 0.1117 - learning_rate: 0.0010\nEpoch 9/10\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 176ms/step - accuracy: 0.9506 - loss: 0.1259 - val_accuracy: 0.9603 - val_loss: 0.1073 - learning_rate: 0.0010\nEpoch 10/10\n\u001b[1m224/224\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 176ms/step - accuracy: 0.9521 - loss: 0.1188 - val_accuracy: 0.9596 - val_loss: 0.1066 - learning_rate: 0.0010\nModel saved.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/output/lstm_model.h5","text/html":"<a href='/kaggle/working/output/lstm_model.h5' target='_blank'>/kaggle/working/output/lstm_model.h5</a><br>"},"metadata":{}},{"name":"stdout","text":"\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\n\nWord2Vec + LSTM Model Accuracy: 0.9596\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.95      0.97      0.96      7006\n           1       0.97      0.95      0.96      7302\n\n    accuracy                           0.96     14308\n   macro avg       0.96      0.96      0.96     14308\nweighted avg       0.96      0.96      0.96     14308\n\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"30528"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import os\nimport zipfile\nfrom IPython.display import FileLink\n\n# Define the output directory and ZIP file name\noutput_dir = '/kaggle/working/output'\nzip_filename = '/kaggle/working/output_files.zip'\n\n# Function to zip the entire folder\ndef zip_folder(folder_path, output_zip):\n    # Create a ZipFile object in write mode\n    with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:\n        # Walk through the directory\n        for root, dirs, files in os.walk(folder_path):\n            for file in files:\n                # Create the full file path\n                file_path = os.path.join(root, file)\n                # Calculate the relative path for the ZIP structure\n                relative_path = os.path.relpath(file_path, folder_path)\n                # Add the file to the ZIP with its relative path\n                zipf.write(file_path, os.path.join(os.path.basename(folder_path), relative_path))\n    print(f\"Created ZIP file: {output_zip}\")\n\n# Check if the output directory exists and has files\nif os.path.exists(output_dir) and os.listdir(output_dir):\n    print(f\"Zipping contents of {output_dir}...\")\n    zip_folder(output_dir, zip_filename)\n    \n    # Display a download link\n    if os.path.exists(zip_filename):\n        display(FileLink(zip_filename))\n    else:\n        print(\"Error: ZIP file was not created.\")\nelse:\n    print(f\"Error: Directory {output_dir} is empty or does not exist.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-02T07:23:54.868724Z","iopub.execute_input":"2025-04-02T07:23:54.869089Z","iopub.status.idle":"2025-04-02T07:24:05.979709Z","shell.execute_reply.started":"2025-04-02T07:23:54.869063Z","shell.execute_reply":"2025-04-02T07:24:05.978732Z"}},"outputs":[{"name":"stdout","text":"Zipping contents of /kaggle/working/output...\nCreated ZIP file: /kaggle/working/output_files.zip\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/output_files.zip","text/html":"<a href='/kaggle/working/output_files.zip' target='_blank'>/kaggle/working/output_files.zip</a><br>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Install required packages\nprint(\"Installing packages...\")\n!pip install newsapi-python -q\nprint(\"Packages installed.\")\n\n# Import libraries\nimport numpy as np\nimport os\nimport re\nfrom multiprocessing import Pool, cpu_count\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(f\"Found input file: {os.path.join(dirname, filename)}\")\n\nimport re\nimport nltk\nimport zipfile\nnltk.download('stopwords')\nnltk.download('wordnet', download_dir='/kaggle/working/nltk_data')\nnltk.download('vader_lexicon')\nnltk.data.path.append('/kaggle/working/nltk_data')\nprint(\"Checking NLTK wordnet resource...\")\nwordnet_zip = '/kaggle/working/nltk_data/corpora/wordnet.zip'\nif os.path.exists(wordnet_zip):\n    print(f\"Unzipping wordnet from {wordnet_zip}...\")\n    with zipfile.ZipFile(wordnet_zip, 'r') as zip_ref:\n        zip_ref.extractall('/kaggle/working/nltk_data/corpora')\n    os.remove(wordnet_zip)\n    print(\"Wordnet unzipped and zip file removed.\")\nelse:\n    print(\"Wordnet already unzipped or not downloaded as zip.\")\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.utils import custom_object_scope\nimport pickle\nfrom newsapi import NewsApiClient\nimport requests\nfrom bs4 import BeautifulSoup\nimport string\n\n# Define a minimal Cast layer as a fallback (only if needed)\nclass Cast(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(Cast, self).__init__(**kwargs)\n    \n    def call(self, inputs):\n        # Let TensorFlow infer dtype from inputs or model context\n        return tf.cast(inputs, dtype=self.dtype_policy.compute_dtype)\n    \n    def get_config(self):\n        return super(Cast, self).get_config()\n    \n    @classmethod\n    def from_config(cls, config):\n        return cls(**config)\n\n# Robust file checking and loading\ndef load_file(file_path, load_func, desc):\n    if os.path.exists(file_path):\n        try:\n            return load_func(file_path)\n        except Exception as e:\n            print(f\"Error loading {desc} from {file_path}: {e}\")\n            return None\n    else:\n        print(f\"{desc} file not found at {file_path}.\")\n        return None\n\n# Load model and tools with error handling\nprint(\"Loading model and tools...\")\nmodel_path = '/kaggle/input/fake/tensorflow2/default/1/lstm_model.h5'\ntokenizer_path = '/kaggle/input/fake/tensorflow2/default/1/tokenizer.pkl'\nscaler_path = '/kaggle/input/fake/tensorflow2/default/1/scaler.pkl'\n\nwith custom_object_scope({'Cast': Cast}):\n    model = load_file(model_path, lambda p: tf.keras.models.load_model(p), \"Model\")\ntokenizer = load_file(tokenizer_path, lambda p: pickle.load(open(p, 'rb')), \"Tokenizer\")\nscaler = load_file(scaler_path, lambda p: pickle.load(open(p, 'rb')), \"Scaler\")\n\nif model is None or tokenizer is None or scaler is None:\n    print(\"Critical files missing or corrupted. Please ensure training script ran successfully.\")\n    raise SystemExit(1)\nprint(\"Model, tokenizer, and scaler loaded successfully.\")\n\n# Constants\nMAX_SEQUENCE_LENGTH = 100\nNUM_FEATURES = 10\nAPI_KEY = '20a033afa85e4b72af903562634d7f6d'  # Replace with your NewsAPI key\nstop_words = set(stopwords.words('english')) - {'not'}\nlemmatizer = WordNetLemmatizer()\nsia = nltk.sentiment.vader.SentimentIntensityAnalyzer()\n\n# Preprocessing and feature extraction with fallbacks\ndef preprocess_text(text):\n    if not isinstance(text, str) or not text.strip():\n        return \"\"\n    try:\n        text = re.sub(r\"[^a-zA-Z\\s]\", \" \", text.lower())\n        words = text.split()\n        return \" \".join(lemmatizer.lemmatize(word) for word in words if word not in stop_words or word == 'not')\n    except Exception as e:\n        print(f\"Error preprocessing text: {e}\")\n        return \"\"\n\ndef extract_numerical_features(text):\n    if not isinstance(text, str):\n        return np.zeros(NUM_FEATURES)\n    try:\n        words = text.split()\n        title = text[:50]  # Rough title approximation\n        return np.array([\n            len(title.split()), len(words), len(title), len(text),\n            sum(1 for c in title if c.isupper()) / len(title) if len(title) > 0 else 0,\n            sum(1 for c in text if c.isupper()) / len(text) if len(text) > 0 else 0,\n            sum(1 for c in title if c in string.punctuation), sum(1 for c in text if c in string.punctuation),\n            sia.polarity_scores(title)['compound'], sia.polarity_scores(text)['compound']\n        ])\n    except Exception as e:\n        print(f\"Error extracting features: {e}\")\n        return np.zeros(NUM_FEATURES)\n\n# Batch prediction with GPU and error handling\ndef predict_batch(texts):\n    try:\n        processed_texts = [preprocess_text(t) for t in texts]\n        seqs = tokenizer.texts_to_sequences(processed_texts)\n        padded_seqs = pad_sequences(seqs, maxlen=MAX_SEQUENCE_LENGTH, padding='post', truncating='post')\n        num_features = scaler.transform(np.array([extract_numerical_features(t) for t in texts]))\n        with tf.device('/GPU:0'):\n            preds = model.predict([padded_seqs, num_features], batch_size=256, verbose=0)\n        return (preds >= 0.5).astype(int).flatten()\n    except Exception as e:\n        print(f\"Prediction error: {e}\")\n        return np.zeros(len(texts), dtype=int)  # Fallback to all 'Fake' if prediction fails\n\n# Fetch news with robust error handling\ndef fetch_news(topic):\n    newsapi = NewsApiClient(api_key=API_KEY)\n    try:\n        response = newsapi.get_everything(q=topic, language='en', page_size=10)\n        articles = []\n        for article in response['articles']:\n            try:\n                resp = requests.get(article['url'], timeout=5)\n                soup = BeautifulSoup(resp.text, 'html.parser')\n                text = \" \".join(p.get_text() for p in soup.find_all('p'))\n                if text.strip():\n                    articles.append(f\"{article['title']} {text}\")\n            except requests.RequestException as e:\n                print(f\"Failed to fetch article {article.get('url', 'unknown')}: {e}\")\n                continue\n        print(f\"Fetched {len(articles)} articles for '{topic}'.\")\n        return articles\n    except Exception as e:\n        print(f\"Error fetching news: {e}\")\n        return []\n\n# Interactive workflow with robustness\nwhile True:\n    try:\n        choice = input(\"Enter 'news' for news fetch or text to classify (or 'exit'): \").strip().lower()\n        if choice == 'exit':\n            break\n        elif choice == 'news':\n            topic = input(\"Enter news topic (e.g., Chandrayaan): \").strip()\n            if topic:\n                articles = fetch_news(topic)\n                if articles:\n                    labels = predict_batch(articles)\n                    for text, label in zip(articles, labels):\n                        print(f\"Text: '{text[:50]}...' -> Predicted: {'Real' if label else 'Fake'}\")\n                else:\n                    print(\"No articles fetched. Try another topic or check API key.\")\n        else:\n            labels = predict_batch([choice])\n            print(f\"Input: '{choice[:50]}...' -> Predicted: {'Real' if labels[0] else 'Fake'}\")\n    except KeyboardInterrupt:\n        print(\"\\nExiting gracefully...\")\n        break\n    except Exception as e:\n        print(f\"Workflow error: {e}. Continuing...\")\n\nprint(\"Program terminated.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}